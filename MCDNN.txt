import numpy
import tensorflow as tf
import keras
from keras.utils import to_categorical
from keras.datasets import mnist
from keras.layers import Input, Conv2D, concatenate, MaxPooling2D, Flatten, BatchNormalization, GlobalMaxPooling2D, Average
from keras.models import Sequential, Model
from keras.layers import Dense
from keras.optimizers import SGD
from keras.layers import Dropout
from keras.utils import np_utils
from keras.preprocessing.image import ImageDataGenerator
# fix random seed for reproducibility
# load data
def LiSHT(x):
  return x * K.tanh(x)

def load_dataset():
  (train_x,train_y), (test_x,test_y) =  mnist.load_data()
  train_x = train_x.reshape((train_x.shape[0], 28, 28, 1))
  test_x = test_x.reshape((test_x.shape[0], 28, 28, 1))
  train_y = to_categorical(train_y)
  test_y = to_categorical(test_y)
  return train_x, train_y, test_x, test_y

def data_prep(train,test):
  # convert from integers to floats
  train_norm = train.astype('float32')
  test_norm = test.astype('float32')
  # normalize to range 0-1
  train_norm = train_norm / 255.0
  test_norm = test_norm / 255.0
  # return normalized images
  return train_norm, test_norm

def define_model(width):
  input = Input(shape= (width,width,1)) 

  conv1_1 = Conv2D(20, kernel_size=(4,4), strides=(1,1), padding= 'same', activation= 'tanh', kernel_initializer= 'he_uniform')(input)
  max1 = MaxPooling2D((2,2), strides = (2,2), padding = 'same')(conv1_1)
  batch1 = BatchNormalization()(max1)
  drop1 = Dropout(0.4)(batch1)
  conv2 = Conv2D(40, kernel_size=(5,5),strides= (1,1),padding= 'same', activation= 'tanh', kernel_initializer= 'he_uniform')(drop1)
  max2 = MaxPooling2D((3,3),strides = (3,3), padding = 'same')(conv2)
  batch2 = BatchNormalization()(max2)
  drop2 = Dropout(0.4)(batch2)
  flat1= Flatten()(drop2)
  dense1 = Dense(150, activation= 'tanh', kernel_initializer= 'he_uniform')(flat1)
  output1 = Dense(10, activation= 'softmax')(dense1)
  

  #input = Input(shape= (width,width,1))
  conv1_2 = Conv2D(20, kernel_size=(4,4), strides=(2,2), padding= 'same', activation= 'tanh', kernel_initializer= 'he_uniform')(input)
  max1 = MaxPooling2D((2,2), strides = (2,2))(conv1_2)
  dense2 = Dense(150, activation= 'tanh', kernel_initializer= 'he_uniform')(flat1)
  output2 = Dense(10, activation= 'softmax')(dense2)

  conv1_3 = Conv2D(20, kernel_size=(4,4), strides=(2,2), padding= 'same', activation= 'tanh', kernel_initializer= 'he_uniform')(input)
  max1 = MaxPooling2D((2,2), strides = (2,2))(conv1_3)
  dense3 = Dense(150, activation= 'tanh', kernel_initializer= 'he_uniform')(flat1)
  output3 = Dense(10, activation= 'softmax')(dense3)


  conv1_4 = Conv2D(20, kernel_size=(4,4), strides=(2,2), padding= 'same', activation= 'tanh', kernel_initializer= 'he_uniform')(input)
  max1 = MaxPooling2D((2,2), strides = (2,2))(conv1_4)
  dense4 = Dense(150, activation= 'tanh', kernel_initializer= 'he_uniform')(flat1)
  output4 = Dense(10, activation= 'softmax')(dense4)


  conv1_5 = Conv2D(20, kernel_size=(4,4), strides=(2,2), padding= 'same', activation= 'tanh', kernel_initializer= 'he_uniform')(input)
  max1 = MaxPooling2D((2,2), strides = (2,2))(conv1_5)
  dense5 = Dense(150, activation= 'tanh', kernel_initializer= 'he_uniform')(flat1)
  output5 = Dense(10, activation= 'softmax')(dense5)


  #concatenated = concatenate([output1,output2,output3,output4,output5])
  ave = Average()([output1, output2, output3, output4, output5])
  #output = Dense(10,activation= 'softmax')(ave)

  #model = Model(inputs = [input_1,input_2,input_3,input_4,input_5], outputs = output )
  model = Model(inputs = input, outputs = ave)

  opt = SGD(lr = 0.0000015, momentum = 0.9)
  model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])
  return model

def run_test_harness():
  train_x, train_y, test_x,test_y = load_dataset()
  train_x,test_x = data_prep(train_x, test_x)
  #model = define_model(28)
  datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, rotation_range =10, zoom_range = 0.1)
  testgen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, rotation_range =10, zoom_range = 0.1)
  it_train = datagen.flow(train_x, train_y, batch_size=64)
  it_test = testgen.flow(test_x, test_y, batch_size=64)
  steps = int(train_x.shape[0] / 64)
  new_model.fit_generator(it_train, steps_per_epoch=steps, epochs=200, validation_data=it_test, verbose=2,shuffle = True)
  new_model.save('final_model.h5')

new_model = tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/final_model (600).h5')

run_test_harness()



